{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "решил взять этот датасет https://www.kaggle.com/colearninglounge/predicting-pulsar-starintermediate\n",
    "В нем собраны данные о звездах и предстоит предсказать превратиться ли звезда в пульсар или нет. Поскольку пульсары достаточно редкие, то данные существенно разрежены.\n",
    "При этом сами данные прдеставляют собой статистические оценки распределения электромагнитных импульсов нейтронных звезд.\n",
    "Первые четыре фичи - это оценки приходящего на змелю импульса от конкртеного объекта, причем насколько я понял испульсы от конкретно пульсаров приходят не с одной частотой и имеют разную форму и могут иметь нехарактерные выбросы. Поэтому астрономы собирают по конкретной звезде сигнатуры импульсов и усредняют их и на выходе получаются 4 первые фичи которые есть в датасете.  \n",
    "  \n",
    "А остальные 4 - оценки DM-SNR curve....насколько я понял это связано тоже с импульсом, только с тем, что импульс приходит с  шумом и на разных частотах, связанно это с ионизаией межзвездного пространства и называется в англоязычных источниках \"dispersion\" - не знаю как наши астрономы это называют, но переводить как дисперсию не совсем корректно как мне кажется. В общем каким-то образом астрономы считают для каждого приходящего сигнала от звезды \"dispersion-measure-signal-to-noise-ratio\" и так же их усредняют. Вот собственно последние 4 фичи как раз и есть статистические оценки этих кривых для каждой звезды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/HW_6/pulsar_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Mean of the integrated profile                  float64\n",
       " Standard deviation of the integrated profile    float64\n",
       " Excess kurtosis of the integrated profile       float64\n",
       " Skewness of the integrated profile              float64\n",
       " Mean of the DM-SNR curve                        float64\n",
       " Standard deviation of the DM-SNR curve          float64\n",
       " Excess kurtosis of the DM-SNR curve             float64\n",
       " Skewness of the DM-SNR curve                    float64\n",
       "target_class                                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.156250</td>\n",
       "      <td>48.372971</td>\n",
       "      <td>0.375485</td>\n",
       "      <td>-0.013165</td>\n",
       "      <td>3.168896</td>\n",
       "      <td>18.399367</td>\n",
       "      <td>7.449874</td>\n",
       "      <td>65.159298</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.968750</td>\n",
       "      <td>36.175557</td>\n",
       "      <td>0.712898</td>\n",
       "      <td>3.388719</td>\n",
       "      <td>2.399666</td>\n",
       "      <td>17.570997</td>\n",
       "      <td>9.414652</td>\n",
       "      <td>102.722975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.585938</td>\n",
       "      <td>53.229534</td>\n",
       "      <td>0.133408</td>\n",
       "      <td>-0.297242</td>\n",
       "      <td>2.743311</td>\n",
       "      <td>22.362553</td>\n",
       "      <td>8.508364</td>\n",
       "      <td>74.031324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       121.156250   \n",
       "1                        76.968750   \n",
       "2                       130.585938   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      48.372971   \n",
       "1                                      36.175557   \n",
       "2                                      53.229534   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                    0.375485   \n",
       "1                                    0.712898   \n",
       "2                                    0.133408   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.013165                   3.168896   \n",
       "1                             3.388719                   2.399666   \n",
       "2                            -0.297242                   2.743311   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                18.399367   \n",
       "1                                17.570997   \n",
       "2                                22.362553   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.449874                      65.159298   \n",
       "1                              9.414652                     102.722975   \n",
       "2                              8.508364                      74.031324   \n",
       "\n",
       "   target_class  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12528, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  примеров много, это хорошо. Посмотрим на баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    11375\n",
       "1.0     1153\n",
       "Name: target_class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Видим существенный дисбаланс, посчти в 10 раз. Попробуем решить задачу PU-learning, но сначала попробуем пофитить данные.\n",
    "#  Честно признаться что делать с такими данными ума не приложу. Но раз они все непрервные и иих мало, то предлагаю \n",
    "#  Для начала отмасштабировать их, а затем к каждой применить преобразование в **2 и логарифмическое преобразование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  посмотрим сколько пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Mean of the integrated profile                     0\n",
       " Standard deviation of the integrated profile       0\n",
       " Excess kurtosis of the integrated profile       1735\n",
       " Skewness of the integrated profile                 0\n",
       " Mean of the DM-SNR curve                           0\n",
       " Standard deviation of the DM-SNR curve          1178\n",
       " Excess kurtosis of the DM-SNR curve                0\n",
       " Skewness of the DM-SNR curve                     625\n",
       "target_class                                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ну в целом встречаются, но их немного....сделаем пайплайн, который будет заменять пропущенные значения на медиану"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  разделим данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, :\" Skewness of the DM-SNR curve\"], df[[\"target_class\"]], \n",
    "                                                    test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceNan(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.median_dict = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            self.median_dict[col] = X[col].median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        out = X.copy()\n",
    "        for col in X.columns:\n",
    "            out.loc[out[col].isna(), col] = self.median_dict[col]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDf(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        out = X.copy()\n",
    "        return pd.DataFrame(out, columns=self.col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyFeatureAll(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        out = X.copy()\n",
    "        for col in out.columns:\n",
    "            out[f\"{col}_squared\"] = out[col] ** 2\n",
    "            out[f\"{col}_log\"] = np.where(out[f\"{col}_squared\"] == 0, \n",
    "                                         0, \n",
    "                                         np.log(out[f\"{col}_squared\"])\n",
    "                                        )\n",
    "        return out\n",
    "\n",
    "#  Поскольку я собираюьс использовать StandartScaler, а там могут присутсвовать отрицательные значения, что для логарифма \n",
    "#  неприемлимо, то в качестве аргумента логарифма я буду передавать квадрат соответсвующей фичи\n",
    "#  полюс учесть вариант с нулем, потому что логарифм нуля не определен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = make_column_transformer(\n",
    "                                 (StandardScaler(), \n",
    "                                  [' Mean of the integrated profile', ' Standard deviation of the integrated profile',\n",
    "                                   ' Excess kurtosis of the integrated profile', ' Skewness of the integrated profile', \n",
    "                                   ' Mean of the DM-SNR curve', ' Standard deviation of the DM-SNR curve', \n",
    "                                   ' Excess kurtosis of the DM-SNR curve', ' Skewness of the DM-SNR curve'])\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engine = make_pipeline(scaler, \n",
    "                               CreateDf([\"mean_of_intprof\", \"std_of_intprof\", \"kurtosis_of_intprof\", \"skewness_of_intprof\",\n",
    "                                         \"mean_of_dmsnr\", \"std_of_dmsnr\", \"kurtosis_of_dmsnr\", \"skewness_of_dmsnr\"]),\n",
    "                               ReplaceNan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_of_intprof</th>\n",
       "      <th>std_of_intprof</th>\n",
       "      <th>kurtosis_of_intprof</th>\n",
       "      <th>skewness_of_intprof</th>\n",
       "      <th>mean_of_dmsnr</th>\n",
       "      <th>std_of_dmsnr</th>\n",
       "      <th>kurtosis_of_dmsnr</th>\n",
       "      <th>skewness_of_dmsnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.769000e+03</td>\n",
       "      <td>8.769000e+03</td>\n",
       "      <td>8769.000000</td>\n",
       "      <td>8.769000e+03</td>\n",
       "      <td>8.769000e+03</td>\n",
       "      <td>8769.000000</td>\n",
       "      <td>8.769000e+03</td>\n",
       "      <td>8769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.917474e-16</td>\n",
       "      <td>-1.733513e-16</td>\n",
       "      <td>-0.033240</td>\n",
       "      <td>-9.422779e-18</td>\n",
       "      <td>3.089228e-18</td>\n",
       "      <td>-0.037475</td>\n",
       "      <td>-2.269063e-16</td>\n",
       "      <td>-0.010248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000057e+00</td>\n",
       "      <td>1.000057e+00</td>\n",
       "      <td>0.931692</td>\n",
       "      <td>1.000057e+00</td>\n",
       "      <td>1.000057e+00</td>\n",
       "      <td>0.959965</td>\n",
       "      <td>1.000057e+00</td>\n",
       "      <td>0.975907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.093953e+00</td>\n",
       "      <td>-3.146608e+00</td>\n",
       "      <td>-2.069390</td>\n",
       "      <td>-5.732479e-01</td>\n",
       "      <td>-4.209666e-01</td>\n",
       "      <td>-0.975739</td>\n",
       "      <td>-2.466672e+00</td>\n",
       "      <td>-1.003284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.006069e-01</td>\n",
       "      <td>-6.092257e-01</td>\n",
       "      <td>-0.395392</td>\n",
       "      <td>-3.161286e-01</td>\n",
       "      <td>-3.634431e-01</td>\n",
       "      <td>-0.595377</td>\n",
       "      <td>-5.584327e-01</td>\n",
       "      <td>-0.631312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.573829e-01</td>\n",
       "      <td>6.148837e-02</td>\n",
       "      <td>-0.239312</td>\n",
       "      <td>-2.549724e-01</td>\n",
       "      <td>-3.334553e-01</td>\n",
       "      <td>-0.405699</td>\n",
       "      <td>2.869776e-02</td>\n",
       "      <td>-0.206107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.301579e-01</td>\n",
       "      <td>6.585041e-01</td>\n",
       "      <td>-0.054473</td>\n",
       "      <td>-1.362838e-01</td>\n",
       "      <td>-2.435483e-01</td>\n",
       "      <td>0.024536</td>\n",
       "      <td>5.326459e-01</td>\n",
       "      <td>0.288401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.045283e+00</td>\n",
       "      <td>6.590582e+00</td>\n",
       "      <td>7.099863</td>\n",
       "      <td>1.066318e+01</td>\n",
       "      <td>6.626952e+00</td>\n",
       "      <td>4.232422</td>\n",
       "      <td>5.827287e+00</td>\n",
       "      <td>10.239105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_of_intprof  std_of_intprof  kurtosis_of_intprof  \\\n",
       "count     8.769000e+03    8.769000e+03          8769.000000   \n",
       "mean      1.917474e-16   -1.733513e-16            -0.033240   \n",
       "std       1.000057e+00    1.000057e+00             0.931692   \n",
       "min      -4.093953e+00   -3.146608e+00            -2.069390   \n",
       "25%      -4.006069e-01   -6.092257e-01            -0.395392   \n",
       "50%       1.573829e-01    6.148837e-02            -0.239312   \n",
       "75%       6.301579e-01    6.585041e-01            -0.054473   \n",
       "max       3.045283e+00    6.590582e+00             7.099863   \n",
       "\n",
       "       skewness_of_intprof  mean_of_dmsnr  std_of_dmsnr  kurtosis_of_dmsnr  \\\n",
       "count         8.769000e+03   8.769000e+03   8769.000000       8.769000e+03   \n",
       "mean         -9.422779e-18   3.089228e-18     -0.037475      -2.269063e-16   \n",
       "std           1.000057e+00   1.000057e+00      0.959965       1.000057e+00   \n",
       "min          -5.732479e-01  -4.209666e-01     -0.975739      -2.466672e+00   \n",
       "25%          -3.161286e-01  -3.634431e-01     -0.595377      -5.584327e-01   \n",
       "50%          -2.549724e-01  -3.334553e-01     -0.405699       2.869776e-02   \n",
       "75%          -1.362838e-01  -2.435483e-01      0.024536       5.326459e-01   \n",
       "max           1.066318e+01   6.626952e+00      4.232422       5.827287e+00   \n",
       "\n",
       "       skewness_of_dmsnr  \n",
       "count        8769.000000  \n",
       "mean           -0.010248  \n",
       "std             0.975907  \n",
       "min            -1.003284  \n",
       "25%            -0.631312  \n",
       "50%            -0.206107  \n",
       "75%             0.288401  \n",
       "max            10.239105  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engine.fit_transform(X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_of_intprof        0\n",
       "std_of_intprof         0\n",
       "kurtosis_of_intprof    0\n",
       "skewness_of_intprof    0\n",
       "mean_of_dmsnr          0\n",
       "std_of_dmsnr           0\n",
       "kurtosis_of_dmsnr      0\n",
       "skewness_of_dmsnr      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engine.fit_transform(X_train).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим как отработала замена пустых значений\n",
    "# мы не можем посмотртеь это по индексам, потому что в тренировочном сете они не по порядку, а в обработанном они как новый\n",
    "# датафрейм создаются. \n",
    "# Но мы можем посчитать количество пустых и посчитать количество медианной оценки в обработанном фреме и посмотреть "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_of_intprof': 0.15738290226572363,\n",
       " 'std_of_intprof': 0.06148837442974762,\n",
       " 'kurtosis_of_intprof': -0.23931228446966626,\n",
       " 'skewness_of_intprof': -0.25497243920583584,\n",
       " 'mean_of_dmsnr': -0.33345529633325094,\n",
       " 'std_of_dmsnr': -0.4056989073055492,\n",
       " 'kurtosis_of_dmsnr': 0.028697762809245207,\n",
       " 'skewness_of_dmsnr': -0.20610736699842797}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в классе по замене пропущенных значений есть параметр обучения, до которого можно достучаться\n",
    "median_dict = feature_engine.get_params()[\"steps\"][-1][-1].median_dict\n",
    "median_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[X_train[\" Standard deviation of the DM-SNR curve\"].isna()].shape[0]\n",
    "#  пропущенные значения по 6 фиче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_engine.fit_transform(X_train)[\"std_of_dmsnr\"] == median_dict[\"std_of_dmsnr\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  811 наверно медиана попала на конкретное значение, поэтому в обработанном фрейме единицу больше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8769"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ну так и есть, наблюдений неченое число"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  посмотрим на всякий случай по другой фиче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[X_train[\" Excess kurtosis of the integrated profile\"].isna()].shape[0]\n",
    "#  пропущенные значения по 3 фиче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1219"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_engine.fit_transform(X_train)[\"kurtosis_of_intprof\"] == median_dict[\"kurtosis_of_intprof\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  отлично, все отрабатывает вроде всерно\n",
    "#  перезапишем трансформер добавив степенное преобразование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engine = make_pipeline(scaler, \n",
    "                               CreateDf([\"mean_of_intprof\", \"std_of_intprof\", \"kurtosis_of_intprof\", \"skewness_of_intprof\",\n",
    "                                         \"mean_of_dmsnr\", \"std_of_dmsnr\", \"kurtosis_of_dmsnr\", \"skewness_of_dmsnr\"]),\n",
    "                               ReplaceNan(),\n",
    "                               PolyFeatureAll()\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_of_intprof</th>\n",
       "      <th>std_of_intprof</th>\n",
       "      <th>kurtosis_of_intprof</th>\n",
       "      <th>skewness_of_intprof</th>\n",
       "      <th>mean_of_dmsnr</th>\n",
       "      <th>std_of_dmsnr</th>\n",
       "      <th>kurtosis_of_dmsnr</th>\n",
       "      <th>skewness_of_dmsnr</th>\n",
       "      <th>mean_of_intprof_squared</th>\n",
       "      <th>mean_of_intprof_log</th>\n",
       "      <th>...</th>\n",
       "      <th>skewness_of_intprof_squared</th>\n",
       "      <th>skewness_of_intprof_log</th>\n",
       "      <th>mean_of_dmsnr_squared</th>\n",
       "      <th>mean_of_dmsnr_log</th>\n",
       "      <th>std_of_dmsnr_squared</th>\n",
       "      <th>std_of_dmsnr_log</th>\n",
       "      <th>kurtosis_of_dmsnr_squared</th>\n",
       "      <th>kurtosis_of_dmsnr_log</th>\n",
       "      <th>skewness_of_dmsnr_squared</th>\n",
       "      <th>skewness_of_dmsnr_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181037</td>\n",
       "      <td>0.218106</td>\n",
       "      <td>-0.294831</td>\n",
       "      <td>-0.320942</td>\n",
       "      <td>-0.263841</td>\n",
       "      <td>0.044253</td>\n",
       "      <td>-0.426087</td>\n",
       "      <td>-0.582606</td>\n",
       "      <td>0.032774</td>\n",
       "      <td>-3.418110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103004</td>\n",
       "      <td>-2.272987</td>\n",
       "      <td>0.069612</td>\n",
       "      <td>-2.664819</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>-6.235653</td>\n",
       "      <td>0.181550</td>\n",
       "      <td>-1.706223</td>\n",
       "      <td>0.339430</td>\n",
       "      <td>-1.080488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.080673</td>\n",
       "      <td>0.674244</td>\n",
       "      <td>-0.238607</td>\n",
       "      <td>-0.276213</td>\n",
       "      <td>-0.358370</td>\n",
       "      <td>-0.593524</td>\n",
       "      <td>0.434472</td>\n",
       "      <td>0.239128</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>-5.034715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076293</td>\n",
       "      <td>-2.573169</td>\n",
       "      <td>0.128429</td>\n",
       "      <td>-2.052379</td>\n",
       "      <td>0.352271</td>\n",
       "      <td>-1.043356</td>\n",
       "      <td>0.188766</td>\n",
       "      <td>-1.667249</td>\n",
       "      <td>0.057182</td>\n",
       "      <td>-2.861514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961009</td>\n",
       "      <td>-0.219836</td>\n",
       "      <td>-0.479055</td>\n",
       "      <td>-0.206964</td>\n",
       "      <td>-0.251355</td>\n",
       "      <td>0.132838</td>\n",
       "      <td>-0.428847</td>\n",
       "      <td>-0.591623</td>\n",
       "      <td>0.923539</td>\n",
       "      <td>-0.079542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042834</td>\n",
       "      <td>-3.150418</td>\n",
       "      <td>0.063179</td>\n",
       "      <td>-2.761776</td>\n",
       "      <td>0.017646</td>\n",
       "      <td>-4.037255</td>\n",
       "      <td>0.183910</td>\n",
       "      <td>-1.693311</td>\n",
       "      <td>0.350018</td>\n",
       "      <td>-1.049770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>-0.417937</td>\n",
       "      <td>-0.329279</td>\n",
       "      <td>-0.289601</td>\n",
       "      <td>-0.121914</td>\n",
       "      <td>-0.277934</td>\n",
       "      <td>-0.475524</td>\n",
       "      <td>0.232780</td>\n",
       "      <td>-1.457662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108425</td>\n",
       "      <td>-2.221701</td>\n",
       "      <td>0.083869</td>\n",
       "      <td>-2.478502</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>-4.208875</td>\n",
       "      <td>0.077247</td>\n",
       "      <td>-2.560744</td>\n",
       "      <td>0.226123</td>\n",
       "      <td>-1.486675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.004375</td>\n",
       "      <td>-0.721643</td>\n",
       "      <td>-0.418720</td>\n",
       "      <td>-0.185203</td>\n",
       "      <td>-0.375168</td>\n",
       "      <td>-0.604979</td>\n",
       "      <td>0.822467</td>\n",
       "      <td>0.512726</td>\n",
       "      <td>1.008769</td>\n",
       "      <td>0.008731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>-3.372603</td>\n",
       "      <td>0.140751</td>\n",
       "      <td>-1.960765</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>-1.005122</td>\n",
       "      <td>0.676452</td>\n",
       "      <td>-0.390893</td>\n",
       "      <td>0.262888</td>\n",
       "      <td>-1.336027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>-0.211982</td>\n",
       "      <td>-2.030838</td>\n",
       "      <td>-0.012646</td>\n",
       "      <td>0.205623</td>\n",
       "      <td>-0.347604</td>\n",
       "      <td>-0.342031</td>\n",
       "      <td>0.174245</td>\n",
       "      <td>-0.158935</td>\n",
       "      <td>0.044936</td>\n",
       "      <td>-3.102507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042281</td>\n",
       "      <td>-3.163424</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>-2.113385</td>\n",
       "      <td>0.116985</td>\n",
       "      <td>-2.145706</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>-3.494587</td>\n",
       "      <td>0.025260</td>\n",
       "      <td>-3.678520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>-0.071878</td>\n",
       "      <td>-0.302066</td>\n",
       "      <td>-0.037593</td>\n",
       "      <td>-0.173809</td>\n",
       "      <td>-0.403042</td>\n",
       "      <td>-0.405699</td>\n",
       "      <td>2.104268</td>\n",
       "      <td>2.279705</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>-5.265567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030209</td>\n",
       "      <td>-3.499602</td>\n",
       "      <td>0.162443</td>\n",
       "      <td>-1.817431</td>\n",
       "      <td>0.164592</td>\n",
       "      <td>-1.804288</td>\n",
       "      <td>4.427942</td>\n",
       "      <td>1.487935</td>\n",
       "      <td>5.197055</td>\n",
       "      <td>1.648092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>-3.896534</td>\n",
       "      <td>-1.677625</td>\n",
       "      <td>4.761961</td>\n",
       "      <td>4.792705</td>\n",
       "      <td>2.076080</td>\n",
       "      <td>1.492015</td>\n",
       "      <td>-1.613207</td>\n",
       "      <td>-0.975166</td>\n",
       "      <td>15.182978</td>\n",
       "      <td>2.720175</td>\n",
       "      <td>...</td>\n",
       "      <td>22.970018</td>\n",
       "      <td>3.134190</td>\n",
       "      <td>4.310109</td>\n",
       "      <td>1.460963</td>\n",
       "      <td>2.226110</td>\n",
       "      <td>0.800256</td>\n",
       "      <td>2.602438</td>\n",
       "      <td>0.956449</td>\n",
       "      <td>0.950949</td>\n",
       "      <td>-0.050295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>-0.213498</td>\n",
       "      <td>0.222297</td>\n",
       "      <td>-0.239312</td>\n",
       "      <td>-0.220054</td>\n",
       "      <td>-0.308202</td>\n",
       "      <td>-0.283934</td>\n",
       "      <td>-0.229892</td>\n",
       "      <td>-0.413254</td>\n",
       "      <td>0.045582</td>\n",
       "      <td>-3.088252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>-3.027761</td>\n",
       "      <td>0.094989</td>\n",
       "      <td>-2.353997</td>\n",
       "      <td>0.080619</td>\n",
       "      <td>-2.518026</td>\n",
       "      <td>0.052850</td>\n",
       "      <td>-2.940293</td>\n",
       "      <td>0.170779</td>\n",
       "      <td>-1.767388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>0.480956</td>\n",
       "      <td>-0.490896</td>\n",
       "      <td>-0.824405</td>\n",
       "      <td>-0.214466</td>\n",
       "      <td>-0.135350</td>\n",
       "      <td>-0.405699</td>\n",
       "      <td>-0.865231</td>\n",
       "      <td>-0.806711</td>\n",
       "      <td>0.231319</td>\n",
       "      <td>-1.463958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045996</td>\n",
       "      <td>-3.079210</td>\n",
       "      <td>0.018320</td>\n",
       "      <td>-3.999784</td>\n",
       "      <td>0.164592</td>\n",
       "      <td>-1.804288</td>\n",
       "      <td>0.748624</td>\n",
       "      <td>-0.289518</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>-0.429581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8769 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_of_intprof  std_of_intprof  kurtosis_of_intprof  \\\n",
       "0            0.181037        0.218106            -0.294831   \n",
       "1           -0.080673        0.674244            -0.238607   \n",
       "2            0.961009       -0.219836            -0.479055   \n",
       "3            0.482473        0.421053            -0.417937   \n",
       "4            1.004375       -0.721643            -0.418720   \n",
       "...               ...             ...                  ...   \n",
       "8764        -0.211982       -2.030838            -0.012646   \n",
       "8765        -0.071878       -0.302066            -0.037593   \n",
       "8766        -3.896534       -1.677625             4.761961   \n",
       "8767        -0.213498        0.222297            -0.239312   \n",
       "8768         0.480956       -0.490896            -0.824405   \n",
       "\n",
       "      skewness_of_intprof  mean_of_dmsnr  std_of_dmsnr  kurtosis_of_dmsnr  \\\n",
       "0               -0.320942      -0.263841      0.044253          -0.426087   \n",
       "1               -0.276213      -0.358370     -0.593524           0.434472   \n",
       "2               -0.206964      -0.251355      0.132838          -0.428847   \n",
       "3               -0.329279      -0.289601     -0.121914          -0.277934   \n",
       "4               -0.185203      -0.375168     -0.604979           0.822467   \n",
       "...                   ...            ...           ...                ...   \n",
       "8764             0.205623      -0.347604     -0.342031           0.174245   \n",
       "8765            -0.173809      -0.403042     -0.405699           2.104268   \n",
       "8766             4.792705       2.076080      1.492015          -1.613207   \n",
       "8767            -0.220054      -0.308202     -0.283934          -0.229892   \n",
       "8768            -0.214466      -0.135350     -0.405699          -0.865231   \n",
       "\n",
       "      skewness_of_dmsnr  mean_of_intprof_squared  mean_of_intprof_log  ...  \\\n",
       "0             -0.582606                 0.032774            -3.418110  ...   \n",
       "1              0.239128                 0.006508            -5.034715  ...   \n",
       "2             -0.591623                 0.923539            -0.079542  ...   \n",
       "3             -0.475524                 0.232780            -1.457662  ...   \n",
       "4              0.512726                 1.008769             0.008731  ...   \n",
       "...                 ...                      ...                  ...  ...   \n",
       "8764          -0.158935                 0.044936            -3.102507  ...   \n",
       "8765           2.279705                 0.005166            -5.265567  ...   \n",
       "8766          -0.975166                15.182978             2.720175  ...   \n",
       "8767          -0.413254                 0.045582            -3.088252  ...   \n",
       "8768          -0.806711                 0.231319            -1.463958  ...   \n",
       "\n",
       "      skewness_of_intprof_squared  skewness_of_intprof_log  \\\n",
       "0                        0.103004                -2.272987   \n",
       "1                        0.076293                -2.573169   \n",
       "2                        0.042834                -3.150418   \n",
       "3                        0.108425                -2.221701   \n",
       "4                        0.034300                -3.372603   \n",
       "...                           ...                      ...   \n",
       "8764                     0.042281                -3.163424   \n",
       "8765                     0.030209                -3.499602   \n",
       "8766                    22.970018                 3.134190   \n",
       "8767                     0.048424                -3.027761   \n",
       "8768                     0.045996                -3.079210   \n",
       "\n",
       "      mean_of_dmsnr_squared  mean_of_dmsnr_log  std_of_dmsnr_squared  \\\n",
       "0                  0.069612          -2.664819              0.001958   \n",
       "1                  0.128429          -2.052379              0.352271   \n",
       "2                  0.063179          -2.761776              0.017646   \n",
       "3                  0.083869          -2.478502              0.014863   \n",
       "4                  0.140751          -1.960765              0.366000   \n",
       "...                     ...                ...                   ...   \n",
       "8764               0.120828          -2.113385              0.116985   \n",
       "8765               0.162443          -1.817431              0.164592   \n",
       "8766               4.310109           1.460963              2.226110   \n",
       "8767               0.094989          -2.353997              0.080619   \n",
       "8768               0.018320          -3.999784              0.164592   \n",
       "\n",
       "      std_of_dmsnr_log  kurtosis_of_dmsnr_squared  kurtosis_of_dmsnr_log  \\\n",
       "0            -6.235653                   0.181550              -1.706223   \n",
       "1            -1.043356                   0.188766              -1.667249   \n",
       "2            -4.037255                   0.183910              -1.693311   \n",
       "3            -4.208875                   0.077247              -2.560744   \n",
       "4            -1.005122                   0.676452              -0.390893   \n",
       "...                ...                        ...                    ...   \n",
       "8764         -2.145706                   0.030361              -3.494587   \n",
       "8765         -1.804288                   4.427942               1.487935   \n",
       "8766          0.800256                   2.602438               0.956449   \n",
       "8767         -2.518026                   0.052850              -2.940293   \n",
       "8768         -1.804288                   0.748624              -0.289518   \n",
       "\n",
       "      skewness_of_dmsnr_squared  skewness_of_dmsnr_log  \n",
       "0                      0.339430              -1.080488  \n",
       "1                      0.057182              -2.861514  \n",
       "2                      0.350018              -1.049770  \n",
       "3                      0.226123              -1.486675  \n",
       "4                      0.262888              -1.336027  \n",
       "...                         ...                    ...  \n",
       "8764                   0.025260              -3.678520  \n",
       "8765                   5.197055               1.648092  \n",
       "8766                   0.950949              -0.050295  \n",
       "8767                   0.170779              -1.767388  \n",
       "8768                   0.650782              -0.429581  \n",
       "\n",
       "[8769 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engine.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ради интереса обучу быстренько модель на решающих деревьях чтобы посмотреть насколько хорошо классический подход работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, max_depth=7, criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe = make_pipeline(feature_engine, forest_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pipeline',\n",
       "                 Pipeline(steps=[('columntransformer',\n",
       "                                  ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                   StandardScaler(),\n",
       "                                                                   [' Mean of '\n",
       "                                                                    'the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Standard '\n",
       "                                                                    'deviation '\n",
       "                                                                    'of the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Excess '\n",
       "                                                                    'kurtosis '\n",
       "                                                                    'of the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Skewness '\n",
       "                                                                    'of the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Mean of '\n",
       "                                                                    'the '\n",
       "                                                                    'DM-SNR '\n",
       "                                                                    'curve',\n",
       "                                                                    ' Standard '\n",
       "                                                                    'deviat...\n",
       "                                  CreateDf(col_names=['mean_of_intprof',\n",
       "                                                      'std_of_intprof',\n",
       "                                                      'kurtosis_of_intprof',\n",
       "                                                      'skewness_of_intprof',\n",
       "                                                      'mean_of_dmsnr',\n",
       "                                                      'std_of_dmsnr',\n",
       "                                                      'kurtosis_of_dmsnr',\n",
       "                                                      'skewness_of_dmsnr'])),\n",
       "                                 ('replacenan', ReplaceNan()),\n",
       "                                 ('polyfeatureall', PolyFeatureAll())])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(criterion='entropy', max_depth=7,\n",
       "                                        n_estimators=500, n_jobs=-1))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pipe.fit(X_train, y_train.to_numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00669327, 0.00184825, 0.00360997, ..., 0.00617197, 0.01746299,\n",
       "       0.39564519])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf_pred = forest_pipe.predict_proba(X_test)[:, 1]\n",
    "forest_clf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9792958268943823"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_score = roc_auc_score(y_test, forest_clf_pred)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  хм.....а судя по всему получился неплохой классификатор....но надо посмотреть на confusion matrix... возможно \n",
    "#  из-за дисбаланса классов у нас такая хорошая оценка выходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.388516, F-Score=0.893, Precision=0.943, Recall=0.847\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, forest_clf_pred)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3388,   18],\n",
       "       [  55,  298]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, forest_clf_pred>thresholds[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ну в целом действительно неплохой классификатор получился. Мы с уверенностью можем вычленить все пульсары из общего массива\n",
    "#  при этом мы очень мало делаем ошибок второго рода, т.е. FP. Думаю для целей разведочного научного исследования это лучше,\n",
    "#  поскольку не нужно тратить ресурсы на то чтобы вычленить FP примеры из предсказанного массива....как если бы precision Был\n",
    "#  бы на уровне 50-60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>0.388516</td>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.847025</td>\n",
       "      <td>0.892537</td>\n",
       "      <td>0.979296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Threshold  Precision    Recall  F1_score   ROC_AUC\n",
       "Random_forest   0.388516   0.943218  0.847025  0.892537  0.979296"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  запишем данные во фрейм\n",
    "model_comparison = pd.DataFrame(np.array([thresholds[ix], precision[ix], recall[ix], fscore[ix], roc_score]).reshape(1, -1), \n",
    "                                columns=[\"Threshold\", \"Precision\", \"Recall\", \"F1_score\", \"ROC_AUC\"], \n",
    "                                index=[\"Random_forest\"])\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  сделаем функцию, которая будет возвращать фрем для обучения\n",
    "def prepare_df_for_pulearner(df, percentage_of_positive, target_col_name):\n",
    "    pu_df = df.copy()\n",
    "    indexes_of_pos_class = pu_df.loc[pu_df[target_col_name] == 1, :].index\n",
    "    indexes_of_neg_class = pu_df.loc[pu_df[target_col_name] == 0, :].index\n",
    "    \n",
    "    num_of_positive_class = len(indexes_of_pos_class)\n",
    "    sample_length = int(num_of_positive_class * percentage_of_positive)\n",
    "    pos_sample_index = np.random.choice(indexes_of_pos_class, sample_length, replace=False)\n",
    "    neg_sample_index = np.random.choice(indexes_of_neg_class, sample_length, replace=False)\n",
    "    \n",
    "    pos_sample_df = pu_df.loc[pos_sample_index, :]\n",
    "    pos_sample_df[\"pu_target_class\"] = 1\n",
    "    \n",
    "    neg_sample_df = pu_df.loc[neg_sample_index, :]\n",
    "    neg_sample_df[\"pu_target_class\"] = -1\n",
    "    \n",
    "    out_df = pos_sample_df.append(neg_sample_df)\n",
    "    out_df = out_df.sample(frac=1)\n",
    "    \n",
    "    print(f\"Used {sample_length} instances of {num_of_positive_class} total positive class\")\n",
    "    return out_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 576 instances of 1153 total positive class\n"
     ]
    }
   ],
   "source": [
    "pu50_train = prepare_df_for_pulearner(df, 0.5, \"target_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 345 instances of 1153 total positive class\n"
     ]
    }
   ],
   "source": [
    "pu30_test = prepare_df_for_pulearner(df, 0.3, \"target_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "      <th>pu_target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11412</th>\n",
       "      <td>91.906250</td>\n",
       "      <td>49.618614</td>\n",
       "      <td>0.563407</td>\n",
       "      <td>0.394458</td>\n",
       "      <td>2.314381</td>\n",
       "      <td>16.086144</td>\n",
       "      <td>10.011777</td>\n",
       "      <td>114.664815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>133.164062</td>\n",
       "      <td>52.981981</td>\n",
       "      <td>-0.132384</td>\n",
       "      <td>-0.493945</td>\n",
       "      <td>27.844482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.141015</td>\n",
       "      <td>2.898546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>28.466537</td>\n",
       "      <td>4.154733</td>\n",
       "      <td>25.624947</td>\n",
       "      <td>25.643813</td>\n",
       "      <td>57.615931</td>\n",
       "      <td>2.477723</td>\n",
       "      <td>5.393948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "11412                        91.906250   \n",
       "12471                       133.164062   \n",
       "3870                         43.000000   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "11412                                      49.618614   \n",
       "12471                                      52.981981   \n",
       "3870                                       28.466537   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "11412                                    0.563407   \n",
       "12471                                   -0.132384   \n",
       "3870                                     4.154733   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "11412                             0.394458                   2.314381   \n",
       "12471                            -0.493945                  27.844482   \n",
       "3870                             25.624947                  25.643813   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "11412                                16.086144   \n",
       "12471                                      NaN   \n",
       "3870                                 57.615931   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "11412                             10.011777                     114.664815   \n",
       "12471                              2.141015                       2.898546   \n",
       "3870                               2.477723                       5.393948   \n",
       "\n",
       "       target_class  pu_target_class  \n",
       "11412           0.0               -1  \n",
       "12471           0.0               -1  \n",
       "3870            1.0                1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pu50_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu50_X_train = pu50_train.iloc[:, :-2]\n",
    "pu50_y_train = pu50_train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu30_X_test = pu30_test.iloc[:, :-2]\n",
    "pu30_y_test = pu30_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  сделаем пайплайн с тем же классификатором как и на базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe_for_PU = make_pipeline(feature_engine, forest_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pipeline',\n",
       "                 Pipeline(steps=[('columntransformer',\n",
       "                                  ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                   StandardScaler(),\n",
       "                                                                   [' Mean of '\n",
       "                                                                    'the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Standard '\n",
       "                                                                    'deviation '\n",
       "                                                                    'of the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Excess '\n",
       "                                                                    'kurtosis '\n",
       "                                                                    'of the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Skewness '\n",
       "                                                                    'of the '\n",
       "                                                                    'integrated '\n",
       "                                                                    'profile',\n",
       "                                                                    ' Mean of '\n",
       "                                                                    'the '\n",
       "                                                                    'DM-SNR '\n",
       "                                                                    'curve',\n",
       "                                                                    ' Standard '\n",
       "                                                                    'deviat...\n",
       "                                  CreateDf(col_names=['mean_of_intprof',\n",
       "                                                      'std_of_intprof',\n",
       "                                                      'kurtosis_of_intprof',\n",
       "                                                      'skewness_of_intprof',\n",
       "                                                      'mean_of_dmsnr',\n",
       "                                                      'std_of_dmsnr',\n",
       "                                                      'kurtosis_of_dmsnr',\n",
       "                                                      'skewness_of_dmsnr'])),\n",
       "                                 ('replacenan', ReplaceNan()),\n",
       "                                 ('polyfeatureall', PolyFeatureAll())])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(criterion='entropy', max_depth=7,\n",
       "                                        n_estimators=500, n_jobs=-1))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pipe_for_PU.fit(pu50_X_train, pu50_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestPU_predict = forest_pipe_for_PU.predict(pu30_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946376811594203"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_score = roc_auc_score(pu30_y_test, forestPU_predict)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=1.000000, F-Score=0.945, Precision=0.978, Recall=0.913\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(pu30_y_test, forestPU_predict)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forest_PU_learne</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.944528</td>\n",
       "      <td>0.946377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Threshold  Precision    Recall  F1_score   ROC_AUC\n",
       "Forest_PU_learne        1.0   0.978261  0.913043  0.944528  0.946377"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pu_model = pd.DataFrame(np.array([thresholds[ix], precision[ix], recall[ix], fscore[ix], roc_score]).reshape(1, -1), \n",
    "                                columns=[\"Threshold\", \"Precision\", \"Recall\", \"F1_score\", \"ROC_AUC\"], \n",
    "                                index=[\"Forest_PU_learne\"])\n",
    "pu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random_forest</th>\n",
       "      <td>0.388516</td>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.847025</td>\n",
       "      <td>0.892537</td>\n",
       "      <td>0.979296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forest_PU_learne</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.944528</td>\n",
       "      <td>0.946377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Threshold  Precision    Recall  F1_score   ROC_AUC\n",
       "Random_forest      0.388516   0.943218  0.847025  0.892537  0.979296\n",
       "Forest_PU_learne   1.000000   0.978261  0.913043  0.944528  0.946377"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison.append(pu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  если смотреть чисто на roc_auc, то модель ожидаемо работает хуже, потому что обучается на меньшем объеме информации.\n",
    "#  но если смотреть на метрики precision recall, то ситуация намного, намного лучше.\n",
    "#  и если precision не сильно изменился, то recall вырос существенно. Т.е. мы лучше стали выделять нужный класс из общего массива\n",
    "#  Ну я думаю это в любом случае связано с обрезанными данными, потому что один из самых простых способов борьбы с несбалансированными\n",
    "# классами, это как раз обрезка классов....в данном случае мы впринципе это и делаем, не думаю что на модель как-то влияет\n",
    "# кодировка на уровне 1/-1, но сам прием интересный)) возьму на вооружение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поэкспериментировать с долей P на шаге 5 (как будет меняться качество модели при уменьшении/увеличении размера P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 115 instances of 1153 total positive class\n",
      "Used 115 instances of 1153 total positive class\n",
      "Used 230 instances of 1153 total positive class\n",
      "Used 230 instances of 1153 total positive class\n",
      "Used 345 instances of 1153 total positive class\n",
      "Used 345 instances of 1153 total positive class\n",
      "Used 461 instances of 1153 total positive class\n",
      "Used 461 instances of 1153 total positive class\n",
      "Used 576 instances of 1153 total positive class\n",
      "Used 576 instances of 1153 total positive class\n",
      "Used 691 instances of 1153 total positive class\n",
      "Used 691 instances of 1153 total positive class\n",
      "Used 807 instances of 1153 total positive class\n",
      "Used 807 instances of 1153 total positive class\n",
      "Used 922 instances of 1153 total positive class\n",
      "Used 922 instances of 1153 total positive class\n",
      "Used 1037 instances of 1153 total positive class\n",
      "Used 1037 instances of 1153 total positive class\n"
     ]
    }
   ],
   "source": [
    "compare_p = pd.DataFrame(columns=[\"Threshold\", \"Precision\", \"Recall\", \"F1_score\", \"ROC_AUC\"])\n",
    "for p in np.arange(0.1, 1, 0.1):\n",
    "    pu_train = prepare_df_for_pulearner(df, p, \"target_class\")\n",
    "    pu_test = prepare_df_for_pulearner(df, p, \"target_class\")\n",
    "    \n",
    "    pu_X_train = pu_train.iloc[:, :-2]\n",
    "    pu_y_train = pu_train.iloc[:, -1]\n",
    "    pu_X_test = pu_test.iloc[:, :-2]\n",
    "    pu_y_test = pu_test.iloc[:, -1]\n",
    "    \n",
    "    forest_pipe_for_PU.fit(pu_X_train, pu_y_train)\n",
    "    forestPU_predict = forest_pipe_for_PU.predict(pu_X_test)\n",
    "    \n",
    "    roc_score = roc_auc_score(pu_y_test, forestPU_predict)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(pu_y_test, forestPU_predict)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    pu_model = pd.DataFrame(np.array([thresholds[ix], precision[ix], recall[ix], fscore[ix], roc_score]).reshape(1, -1), \n",
    "                                columns=[\"Threshold\", \"Precision\", \"Recall\", \"F1_score\", \"ROC_AUC\"], \n",
    "                                index=[f\"P_rate={p:%}\"])\n",
    "    compare_p = compare_p.append(pu_model)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_rate=10.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.921739</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.930435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=20.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.939130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=30.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.910145</td>\n",
       "      <td>0.926254</td>\n",
       "      <td>0.927536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=40.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960648</td>\n",
       "      <td>0.900217</td>\n",
       "      <td>0.929451</td>\n",
       "      <td>0.931670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=50.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962433</td>\n",
       "      <td>0.934028</td>\n",
       "      <td>0.948018</td>\n",
       "      <td>0.948785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=60.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974085</td>\n",
       "      <td>0.924747</td>\n",
       "      <td>0.948775</td>\n",
       "      <td>0.950072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=70.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.924411</td>\n",
       "      <td>0.943110</td>\n",
       "      <td>0.944238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=80.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964490</td>\n",
       "      <td>0.913232</td>\n",
       "      <td>0.938162</td>\n",
       "      <td>0.939805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_rate=90.000000%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967677</td>\n",
       "      <td>0.923819</td>\n",
       "      <td>0.945239</td>\n",
       "      <td>0.946480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Threshold  Precision    Recall  F1_score   ROC_AUC\n",
       "P_rate=10.000000%        1.0   0.938053  0.921739  0.929825  0.930435\n",
       "P_rate=20.000000%        1.0   0.963303  0.913043  0.937500  0.939130\n",
       "P_rate=30.000000%        1.0   0.942943  0.910145  0.926254  0.927536\n",
       "P_rate=40.000000%        1.0   0.960648  0.900217  0.929451  0.931670\n",
       "P_rate=50.000000%        1.0   0.962433  0.934028  0.948018  0.948785\n",
       "P_rate=60.000000%        1.0   0.974085  0.924747  0.948775  0.950072\n",
       "P_rate=70.000000%        1.0   0.962581  0.924411  0.943110  0.944238\n",
       "P_rate=80.000000%        1.0   0.964490  0.913232  0.938162  0.939805\n",
       "P_rate=90.000000%        1.0   0.967677  0.923819  0.945239  0.946480"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  в целом думаю понятно что с ростом количества примеров растет и качество модели.....в основном конечно recall поскольку \n",
    "#  это основная мтерика на которую нужно обращать внимание при попытке выделить положительные классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
