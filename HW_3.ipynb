{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./train_case2.csv\", delimiter=\";\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "id                                                                          \n",
       "0   18393       2     168    62.0    110     80            1     1      0   \n",
       "1   20228       1     156    85.0    140     90            3     1      0   \n",
       "2   18857       1     165    64.0    130     70            3     1      0   \n",
       "\n",
       "    alco  active  cardio  \n",
       "id                        \n",
       "0      0       1       0  \n",
       "1      0       1       1  \n",
       "2      0       0       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, \"age\":\"active\"], df[\"cardio\"], random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем транформер для колонок, категориальные трансформируем с помощью OneHot, непрерывные с помощью StandartScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans = make_column_transformer(\n",
    "                                    (OneHotEncoder(), [\"gender\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\"]),\n",
    "                                    (StandardScaler(), [\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\"])\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем пайплайн для логрес модели, обучаем ее делаем "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_res = LogisticRegression(C=0.7, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logres_pipe = make_pipeline(col_trans, log_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score for LogRess is 0.77946 mean with 0.00564 standart deviation\n"
     ]
    }
   ],
   "source": [
    "cv_lr_scores = cross_val_score(logres_pipe, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Cross-validation score for LogRess is {np.mean(cv_lr_scores):.5f} \"\n",
    "      f\"mean with {np.std(cv_lr_scores):.5f} standart deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['gender', 'cholesterol',\n",
       "                                                   'gluc', 'smoke', 'alco']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'height', 'weight',\n",
       "                                                   'ap_hi', 'ap_lo'])])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.7, n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logres_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = logres_pipe.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# найдем лучший порог для precision&recall и оценим roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_threshold(y_test, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, lr_pred)\n",
    "    fscore = 2*(precision * recall) / (2*precision + recall)\n",
    "    best = np.argmax(fscore)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    return thresholds[best], precision[best], recall[best], fscore[best], roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.59731 recall=0.91821, fscore=0.51917, threshold=0.33337, roc_auc=0.78382\n"
     ]
    }
   ],
   "source": [
    "threshold_lr, precision_lr, recall_lr, f_score_lr, roc_auc_lr = best_threshold(y_test, lr_pred)\n",
    "print(f\"Precision={precision_lr:.5f} recall={recall_lr:.5f}, fscore={f_score_lr:.5f}, threshold={threshold_lr:.5f}, \"\n",
    "      f\"roc_auc={roc_auc_lr:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если смотреть на roc_auc то может показаться что модель дает хорошую прогнозную силу. и это действительно так,\n",
    "# пока мы не посмотрим на оценку Precision. recall дает достаточно хороший результат, что говорит о том, что модель выбирает\n",
    "# почти все классы с меткой 1, но precision на уровне 60% говорит о том, что модель достаточно много классов оценивает как\n",
    "# ложноположительные. Возможно с точки зрения оценки кардиозаболеваний такой подход оправдан, лучше отправить здорового\n",
    "# человека на дополнительные исследования, чем потом лечить хронического. Т.е. в данном случае модель\n",
    "# минимизирует ошибку первого рода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем такой же пайплайн для RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=150, n_jobs=-1, max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_pipe = make_pipeline(col_trans, rand_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score for RandomForest is 0.79821 mean with 0.00512 standart deviation\n"
     ]
    }
   ],
   "source": [
    "cv_rf_scores = cross_val_score(rand_forest_pipe, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Cross-validation score for RandomForest is {np.mean(cv_rf_scores):.5f} \"\n",
    "      f\"mean with {np.std(cv_rf_scores):.5f} standart deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как видно на этапе кросс-валидации оценка случайного леса чуть лучше чем логистической регрессии. Чуть выше оценка плюс \n",
    "# чуть меньше ее разброс, однако оценка идет для roc_auс, посмотрим на остальные метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['gender', 'cholesterol',\n",
       "                                                   'gluc', 'smoke', 'alco']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'height', 'weight',\n",
       "                                                   'ap_hi', 'ap_lo'])])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=7, n_estimators=150,\n",
       "                                        n_jobs=-1))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rand_forest_pipe.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.59731 recall=0.91821, fscore=0.51917, threshold=0.33337, roc_auc=0.80074\n"
     ]
    }
   ],
   "source": [
    "threshold_rf, precision_rf, recall_rf, f_score_rf, roc_auc_rf = best_threshold(y_test, rf_pred)\n",
    "print(f\"Precision={precision_rf:.5f} recall={recall_rf:.5f}, fscore={f_score_rf:.5f}, threshold={threshold_rf:.5f}, \"\n",
    "      f\"roc_auc={roc_auc_rf:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем пайплайн для градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost = GradientBoostingClassifier(n_estimators=150, max_depth=7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_pipe = make_pipeline(col_trans, grad_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score for GradientBoost is 0.79677 mean with 0.00438 standart deviation\n"
     ]
    }
   ],
   "source": [
    "cv_gb_scores = cross_val_score(grad_boost_pipe, X_train, y_train, cv=10, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"Cross-validation score for GradientBoost is {np.mean(cv_gb_scores):.5f} \"\n",
    "      f\"mean with {np.std(cv_gb_scores):.5f} standart deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['gender', 'cholesterol',\n",
       "                                                   'gluc', 'smoke', 'alco']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'height', 'weight',\n",
       "                                                   'ap_hi', 'ap_lo'])])),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(max_depth=7, n_estimators=150,\n",
       "                                            random_state=42))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred = grad_boost_pipe.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.59731 recall=0.91821, fscore=0.51917, threshold=0.33337, roc_auc=0.79923\n"
     ]
    }
   ],
   "source": [
    "threshold_gb, precision_gb, recall_gb, f_score_gb, roc_auc_gb = best_threshold(y_test, gb_pred)\n",
    "print(f\"Precision={precision_gb:.5f} recall={recall_gb:.5f}, fscore={f_score_gb:.5f}, threshold={threshold_gb:.5f}, \"\n",
    "      f\"roc_auc={roc_auc_gb:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\"Precision\": [precision_lr, precision_rf, precision_gb],\n",
    "                           \"Recall\": [recall_lr, recall_rf, recall_gb],\n",
    "                           \"F1-score\": [f_score_lr, f_score_rf, f_score_gb],\n",
    "                           \"threshold\": [threshold_lr, threshold_rf, threshold_gb],\n",
    "                           \"roc_auc\": [roc_auc_lr, roc_auc_rf, roc_auc_gb]},\n",
    "                          index=[\"LogisticRegression\", \"RandomForest\", \"GradientBoosting\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>threshold</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.597309</td>\n",
       "      <td>0.918209</td>\n",
       "      <td>0.519166</td>\n",
       "      <td>0.333367</td>\n",
       "      <td>0.783817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.597309</td>\n",
       "      <td>0.918209</td>\n",
       "      <td>0.519166</td>\n",
       "      <td>0.333367</td>\n",
       "      <td>0.800745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.597309</td>\n",
       "      <td>0.918209</td>\n",
       "      <td>0.519166</td>\n",
       "      <td>0.333367</td>\n",
       "      <td>0.799230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Precision    Recall  F1-score  threshold   roc_auc\n",
       "LogisticRegression   0.597309  0.918209  0.519166   0.333367  0.783817\n",
       "RandomForest         0.597309  0.918209  0.519166   0.333367  0.800745\n",
       "GradientBoosting     0.597309  0.918209  0.519166   0.333367  0.799230"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# эмммм немного странные метрики получились. Но при этом уровень roc_auc все же разный. Как мне кажется это связано с масштабом \n",
    "# предсказаний, возможно модели делают примерно одинаковые TP и TN предсказания, но различающиеся на несколько единиц \n",
    "# и из-за этого даже с учетом 6 знаков после запятой оценки precision и recall не улавливают данные колебания\n",
    "# roc_auc ведет себя немного по другому и указывают на определенные различия в моделях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого).\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно).\n",
    "Допустим, у нас две модели:\n",
    "\n",
    "первая помечает 100 объектов как класс 1, но TP = 90  \n",
    "вторая помечает 1000 объектов как класс 1, но TP такой же - 90  \n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно стоит промоделировать сам процесс расчета метрик, хотябы на словах\n",
    "При использовании precision и recall вторая метрика дает нам оценку предсказательной силы, а первая не дает записать все объекты в целевой класс.   \n",
    "В случае с первой моделью Precision=90/100=0.9, recall=90/100=0.9  \n",
    "В случае со второй моделью Precision=90/1000=0.09, recall=90/100=0.9\n",
    "И если выбирать на основании чисто этих метрик, предпочтительней будет первая модель, потому что она меньше ошибается в случае ложноположительных оценок. На графике линия второй модели будет лежать ниже линии первой модели.  \n",
    "\n",
    "В случае с roc_auc будет следующая картинка\n",
    "Перед построением кривой выданные ответы будут проранжированы по убыванию, соответсвенно если представить таблицу, то вверху  у нас будет положительные ответы (100 для первой модели, 1000 для второй), а далее отрицательные ответы, при этом сама сетка построения кривой будет разбита на 100 вертикальных линий (правильно положительные ответы) и 99900 горизонтальных (правильно отрицательные) по которым и будет проходить кривая. \n",
    "При построении кривой по первой модели скорее всего линия резко пойдет вверх и дойдет или почти дойдет до 0.9 (поскольку мы ранжируем первые 100 положительных ответов), а дальше будет двигаться вправо.  А в случае со второй моделью, она также сначала пойдет вверх до 0.9 и далее так же пойдет вправо, потому что остальные 910 объектов истино отрицательные....возможно эти две линии не будут похожи друг на друга, но будут очень близки и соответсвенно auc будет различаться не сильно между ними и выбор оптимальной модели будет затруднителен. Поэтому с точки зрения дисбаланса классов лучшим выбором является precision_recall для оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
